---
layout: post
title: 微调llama3
date: 2024-11-26 13:32 +0800
excerpt: "微调llama3"
---

# 用到的工具
1. https://github.com/streamlit/streamlit

# 步骤
1. wget --no-check-certificate https://files.junyao.tech/uPic/llama3-ft.zip
1. mkdir llama3-ft
1. mv llama3-ft.zip llama3-ft
1. cd llama3-ft
1. unzip llama3-ft.zip
1. wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2024.06-1-Linux-x86_64.sh
1. chmod +x Anaconda3-2024.06-1-Linux-86_64.sh
1. ./Anaconda3-2024.06-1-Linux-86_64.sh
1. conda init
1. conda activate
1. pip install -r requirements.txt
1. python train.py
1. 

# 结果
1. 第一次，在M2上训练失败. 下面的错误绕不过去，把`device`设置为`cpu`,设置为`mps`都不行。
   ～～～
   NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
   ～～～
1. 第二次， 到阿里云上去搞。抛内存不够的错误。8G内存。
   ~~~sh
    RuntimeError: unable to mmap 4999802720 bytes from file <./models/model/LLM-Research/Meta-Llama-3-8B-Instruct/model-00002-of-00004.safetensors>: Cannot allocate memory (12)
   ~~~
1. 第三次, 还是回到M2，把device_map参数设置为'cpu', 可以跑了。后面抛OOM错误。
   ~~~
    model = AutoModelForCausalLM.from_pretrained(model_path, device_map="cpu", torch_dtype=torch_dtype)
    ...
    # 加载模型
    model = AutoModelForCausalLM.from_pretrained(model_path, device_map="cpu", torch_dtype=torch_dtype)
   ~~~
1. 改成'mps', Metal Performance Shaders (MPS). MacBook Air M2, 16G, 374s一次迭代，完成699次迭代要72h32m。太慢了。回家用显卡玩玩看。
    1. 跑第4轮的时候抛错了：`RuntimeError: MPS backend out of memory (MPS allocated: 17.70 GB, other allocations: 101.23 MB, max allowed: 18.13 GB). Tried to allocate 454.03 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).`
    1. 
1. 第四次，租了一个显卡, 24G显卡。1s/it, 12分钟能跑完跑完699次迭代.显存占用21225MiB，跑到后面24G显存被占满了. 内存占用14.9GiB. 
    1. 抛错: `RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)`

# 效果评估
问"你是谁？"


回答
~~~
我是甄嬛，家父是大理寺少卿甄远道。皇上是不是爱惜才之体，宁可让臣妾身受罪于法网，也不愿伤了臣妾身孕之身？皇上，臣妾是皇上的宠妃，臣妾的孩子是皇上的孩子，皇上不能让臣妾身受罪于法网，臣妾的孩子不能因无故而失去皇上的名位。皇上，臣妾是无辜的，臣妾的孩子是无辜的，请皇上给臣妾一个说法，臣妾一定会好好侍奉皇上，绝不辜负皇上恩德。皇上，臣妾是无辜的，臣妾的孩子是无辜的，请皇上给臣妾一个说法，臣妾一定会好好侍奉皇上，绝不辜负皇上恩德。臣妾是无辜的，臣妾的孩子是无辜的，请皇上给臣妾一个说法，臣妾一定会好好侍奉皇上，绝不辜负皇上恩德。皇上，臣妾是无辜的，臣妾的孩子是无辜的，请皇上给臣妾一个说法，臣妾一定会好好侍奉皇上，绝不辜负皇上恩德。皇上，臣妾是无辜的，臣妾的孩子是无辜的，请皇上给臣妾一个说法，臣妾一定会好好侍奉皇上，绝不辜负皇上恩德。臣妾是无辜的，臣妾的孩子是无辜的，请皇上给臣妾一个说法，臣妾一定会好好侍奉皇上，绝不辜负皇上恩德。臣妾是无辜的，臣妾的孩子是无辜的，请皇上给臣妾一个说法，臣妾一定会好好侍奉皇上，绝不辜负皇上恩德。臣妾是
~~~


1. 能回答中文，并且回答的是甄嬛里面的话语。
1. 回复内容太多，有点啰嗦。
1. 回答的内容重复太多.“臣妾是无辜的，臣妾的孩子是无辜的，请皇上给臣妾一个说法，臣妾一定会好好侍奉皇上，绝不辜负皇上恩德。”这句话被重复了7次。这是一个问题，需要解决。原因未知.
1. 回答的句子有断句的问题。可以看到回答的末尾, "臣妾是"，然后就突然结束了，话没有说完整。这个问题需要解决。原因目前未知。
1. 目前看下来更像是关键词匹配。
1. CPU微调很慢. 回头试试Unsloth做提速看看。
    1. [Unsloth微调Llama3-8B，提速44.35%，节省42.58%显存，最少仅需7.75GB显存](https://www.53ai.com/news/qianyanjishu/1755.html)
1. 需要和官方训练的嬛嬛对比一下效果，看差在哪地方。
    1. OPenXLab Chat嬛嬛 https://openxlab.org.cn/apps/detail/BYCJS/Chat_huanhuan
1. 微调，让嬛嬛更温和或者更暴躁.  使用 Transformers 的 Trainer 进行微调，具体脚本可参考[internlm2-chat-lora](https://github.com/KMnO4-zx/xlab-huanhuan/blob/master/train/internlm2-chat-lora.ipynb)，该脚本在train文件夹下。脚本内有较为详细的注释。
1. 没有benchmark数据，需要有一个标准化的评分方法，出benchmark数据。
    1. 这里有对嬛嬛进行评测的方法。[Lmdeploy&opencompass 量化以及量化评测](https://github.com/KMnO4-zx/xlab-huanhuan?tab=readme-ov-file#lmdeployopencompass-%E9%87%8F%E5%8C%96%E4%BB%A5%E5%8F%8A%E9%87%8F%E5%8C%96%E8%AF%84%E6%B5%8B)
1. 训练中断以后怎么resume?

基于Llama3 8B训练的嬛嬛的聊天效果。
![huanhuan](/assets/img/llama3-ft/huanhuan-ft.png)

InternLM2的聊天效果. https://openxlab.org.cn/apps/detail/BYCJS/Chat_huanhuan
![InternLM2](/assets/img/llama3-ft/InternLM2-chat-7B-QLora.png)


# 参考链接：
1. https://junyao.tech/posts/e45a9231.html , 嬛嬛训练教程.
2. https://github.com/KMnO4-zx , 这个github非常厉害。
1. https://github.com/liguodongiot/llm-action, 锐哥推荐的llm微调教程。
1. https://github.com/liguodongiot/llm-resource, 资源链接比较多。
1. LoRA 的全称是 Low-Rank Adaptation (低秩适配)，它是一种 Parameter-Efficient Fine-Tuning (参数高效微调，PEFT) 方法，即在微调时只训练原模型中的部分参数，以加速微调的过程。
1. 为什么不用prompt方法？https://qiankunli.github.io/2023/10/29/llm_finetune_theory.html
1. [小白必备】Meta祭出三篇最详尽的LLaMA微调指南](https://mp.weixin.qq.com/s/Mnp7XflcK-BkSR3SzGk8Eg)
1. [Meta - Methods for adapting large language models - Part 1](https://ai.meta.com/blog/adapting-large-language-models-llms/)
1. 部分lora代码和讲解参考仓库：https://github.com/zyds/transformers-code.git
1. https://github.com/datawhalechina/self-llm , 

# 关于`dataset/huanhuan.json`

1. 总共有3729组对话，一问一答的形式。 `instruction`是问题，`output` 是回答。 “input” 通常用于补充提供额外的相关信息或者上下文内容，以帮助生成更贴合具体情境、更准确的 “output”（回答）。比如在一些场景下， “instruction” 提出了一个比较宽泛的问题，那可以通过 “input” 进一步限定范围、给出具体的背景条件等。举个例子，如果 “instruction” 是 “请推荐一部电影”，“input” 就可以是 “我喜欢科幻题材，要有精彩的特效场面”，这样基于 “input” 所提供的这些额外信息，就能生成更符合特定喜好的 “output”（对应的电影推荐回答）。
    ~~~json
        {
            "instruction": "小姐，别的秀女都在求中选，唯有咱们小姐想被撂牌子，菩萨一定记得真真儿的——",
            "input": "",
            "output": "嘘——都说许愿说破是不灵的。"
        }
    ~~~
1. `dataset/huanhuan.json`里面把下面的内容重复了一百来遍, 在json最后面可以看到:
   ~~~json
    {
        "instruction": "你好",
        "input": "",
        "output": "皇上好，我是甄嬛，家父是大理寺少卿甄远道。"
    }
   ~~~
1. 