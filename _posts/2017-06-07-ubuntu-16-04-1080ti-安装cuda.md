---
layout: post
title: ubuntu 16.04 1080Ti 安装Cuda和cuDNN 搭建机器学习显卡加速环境
categories:
- 机器学习
tags:
- cuda
- tensorflow
- cuDNN
excerpt: "2019.06.11更新,添加了超级省事的环境搭建方法. 添加了从nvidia下载并安装官方driver,更新通过docker配置CUDA和cuDNN的方法, 建议都用docker做CUDA和cuDNN的环境搭建,非常方便,1个小时搞定"

---

 `2019.06.11更新`, 新加了从nvidia下载并安装官方driver，更新通过docker配置CUDA和cuDNN的方法, 建议都用docker做CUDA和cuDNN的环境搭建， 非常方便，1个小时搞定。不再需要第三方的显卡驱动，省事省心。

这次更新以后大家只用安装官方驱动(第一步),然后运行官方docker即可顺利跑起来深度学习环境，整个流程简化非常大，并且成功率非常高(100%)。

------

前段时间做自动摘要和自动翻译，跑深度学习的算法，在亚马逊g2上搭过一次 ubuntu 16.04 + CUDA 8.0 + cuDNN 5.1, 走了不少弯路. 亚马逊的g2太贵，4GB显卡版本0.7美元一小时，一个月就够买一台新机器了，并且4G显存的机器跑自动摘要跑着跑着就挂了，内存不够用，所以配了一台设备, GTX 1080 Ti, Intel I7, 32G 内存。 没有想到第二次搭建居然又反反复复搞了几天才搞定。

这次最主要的问题是UEFI secure boot， 没有在启动的时候改启动设置禁止secure boot, 导致第三方驱动不允许加载，系统无法正常识别显卡，浪费了不少时间。
# 硬件配置
1. ASUS GTX 1080Ti, 11g公版。
2. ASUS Z170 A主板
3. 内存 2*16G
4. 128 SSD + 4T HDD
5. CPU i7 6700K

# 第一步: 手动装nvidia显卡驱动（这一步要留心,建议把secure boot禁掉）
无论你后面选择自己配置CUDA和cuDNN还是用docker, 这第一步都得做。NVidia Driver必须装在host里面。

`secure boot`模式下会导致第三方驱动无法加载，建议把UEFI Secure Boot 禁用。你可以搜`主板型号+disable secure boot`查看怎么禁用secure boot.

1. 去NVidia官网选择你要下载的驱动类型，[NVIDIA DRIVERS Linux x64](https://www.nvidia.com/Download/index.aspx?lang=en-us), 参数选择如下:
	1. Product Type: GeForce
	2. Product Series: GeForce 10 Series
	3. Product : GeForce GTX 1080Ti
	4. Operating System: Linux 64 bit
	5. Download Type: Game Ready Driver
	6. Language: English
2. 下载驱动: 搜索到以后在结果页面下载一个类似	`NVIDIA-Linux-x86_64-430.26.run`的文件. 如果你的环境和本文的一样，你可以直接下载[NVIDIA-Linux-x86_64-430.26.run](https://www.nvidia.com/content/DriverDownload-March2009/confirmation.php?url=/XFree86/Linux-x86_64/430.26/NVIDIA-Linux-x86_64-430.26.run&lang=us&type=TITAN)

3. 修改文件权限：`chmod 777 NVIDIA-Linux-x86_64-430.26.run`
4. 安装驱动： `sudo ./NVIDIA-Linux-x86_64-430.26.run`
	1. 如果遇到X ServerError, 请用按第二步说明来停止x server:
		~~~
			ERROR: You appear to be running an X server; please exit X before installing.For further details, please see the section INSTALLING THE NVIDIA DRIVER in the README available on the Linux driver
         	download page at www.nvidia.com.
		~~~
	2. 停止X Server步骤:
		1. Ctrl + Alt + F1 切换到terminal
		2. 登录terminal
		3. `sudo service lightdm stop` 停止x server。 通过`Ctrl + Alt + F7`来检查x server是否关闭, 这是xorg session.
		4. 安装驱动
		5. 启动x server: `sudo service lightdm start`
5. 重启机器:`sudo restart -r now`
6. 检查驱动是否正常安全:
	1. 可以检查ubuntu desktop里面的display，看是否能正常显示高清分辨率(比如1920x1080). VGA兼容模式下是不能正常支持1920x1080的
	2. 也可以在命令行里面输入`nvidia-smi`, 查看显卡是否正常工作:
		~~~
			$ nvidia-smi
			Tue Jun 11 14:27:31 2019
			+-----------------------------------------------------------------------------+
			| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |
			|-------------------------------+----------------------+----------------------+
			| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
			| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
			|===============================+======================+======================|
			|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |
			| 23%   28C    P8     9W / 250W |    339MiB / 11175MiB |      0%      Default |
			+-------------------------------+----------------------+----------------------+

			+-----------------------------------------------------------------------------+
			| Processes:                                                       GPU Memory |
			|  GPU       PID   Type   Process name                             Usage      |
			|=============================================================================|
			|    0      1641      G   /usr/lib/xorg/Xorg                           165MiB |
			|    0      3495      G   compiz                                       171MiB |
			+-----------------------------------------------------------------------------+
		~~~
7. 驱动安装成功。进入下一步。

# 第二步, CUDA/cuDNN环境搭建
有两种选择，nvidia-docker直接用和手动搭环境。

强烈建议用第一种方法，可以直接用，省去无数的配置烦恼。

## 第一种方法: nvidia-docker gpu

nvidia-docker把CUDA和cuDNN环境都配好打包成docker发布出来了，我们就可以省去那些烦人的环境搭建过程。环境搭建是一件费力有没有收益的事情，能不做尽量不做。不得不说docker真是一个好东西！

1. 安装docker, nvidia-docker依赖与docker. docker的安装按[官方文档](https://docs.docker.com/install/linux/docker-ce/ubuntu/)走即可.
2. 安装nvidia-docker. 请按照[nvidia-docker](https://github.com/NVIDIA/nvidia-docker)的说明安装nvidia-docker, nvidia-docker实际上是一个docker里面的驱动衔接层，用来桥接host里面的GPU Driver. nvidia-docker ubuntu的安装步骤贴下面:
	~~~
	# If you have nvidia-docker 1.0 installed: we need to remove it and all existing GPU containers
	docker volume ls -q -f driver=nvidia-docker | xargs -r -I{} -n1 docker ps -q -a -f volume={} | xargs -r docker rm -f
	sudo apt-get purge -y nvidia-docker

	# Add the package repositories
	curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | \
  	sudo apt-key add -
	distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
	curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  	sudo tee /etc/apt/sources.list.d/nvidia-docker.list
	sudo apt-get update

	# Install nvidia-docker2 and reload the Docker daemon configuration
	sudo apt-get install -y nvidia-docker2
	sudo pkill -SIGHUP dockerd

	# Test nvidia-smi with the latest official CUDA image
	docker run --runtime=nvidia --rm nvidia/cuda:9.0-base nvidia-smi
	docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi
	~~~
   
如果你遇到`Unknown runtime specified nvidia.`这种错误，请看下面的解决方法.

### nvidia-docker验证及问题诊断

上面已经安装好nvidia-docker, 接下来就验证一下是否一切OK。

#### 验证nvidia-docker

正常情况下运行`docker run --runtime=nvidia --rm nvidia/cuda:9.0-base nvidia-smi`或者`docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi`会打印类似下面的信息
~~~
Status: Downloaded newer image for nvidia/cuda:9.0-base
Tue Jun 11 07:33:37 2019
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |
| 23%   31C    P8    10W / 250W |     62MiB / 11175MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+
~~~
看到上面的输出说明你的环境已经搭建成功!

#### 验证tensorflow-gpu docker

运行下面的脚本看是否有抛错，如果没有则tensorflow-gpu正常运行 ：
~~~
docker run --runtime=nvidia -it --rm tensorflow/tensorflow:latest-gpu \
   python -c "import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))"
~~~

也可以自己进入tensorflow 环境运行自己的代码:
~~~
docker run --runtime=nvidia -it tensorflow/tensorflow:latest-gpu bash
~~~

#### 问题解决。
下面是你可能会遇到的问题及解决办法:

1. `Unknown runtime specified nvidia.` 错误: 
   运行`docker run --runtime=nvidia --rm nvidia/cuda:9.0-base nvidia-smi`的时候抛错: docker: Error response from daemon: Unknown runtime specified nvidia.
	1. 检查daemon.json, `cat /etc/docker/daemon.json`, 把下面的内容加入到deamon.json里面去
	  ~~~
	  "runtimes": {
        "nvidia": {
            "path": "nvidia-container-runtime",
            "runtimeArgs": []
        }
    }
	  ~~~
	2. 重启系统，或者重启daemon
	~~~sh
		sudo systemctl daemon-reload
		sudo systemctl restart docker
	~~~ 

## 第二种方法: 手动安装环境(不建议)
这种方法非常麻烦，经常出现版本不对，不兼容，链接找不到，环境变量不对，还有，有些repository因为某些原因无法访问，每一个小细节都可能导致你失败。如果时间不充裕，网络翻墙不行(你还得懂命令行翻墙)， 建议不要尝试。

### 安装cuda-toolkit
1. 安装纯净的ubuntu server 16.04 amd64
 * 安装的时候勾上open-ssh，其它的都不用勾。
 * 不装desktop, 装了desktop以后装显卡驱动会很麻烦, 因为ubuntu上面安装n卡驱动需要把图形界面禁掉以后接入tty才好安装, 相当麻烦。
 
1. sudo apt-get install build-essential, 安装基础编译环境
2. 安装cuda。 这一步的说明来自于 https://developer.nvidia.com/cuda-downloads
	
	1. 下载网络安装包 `wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb`
	2. `sudo dpkg -i cuda-repo-ubuntu1604_8.0.61-1_amd64.deb`
	3. `sudo apt-get update`
	4. `sudo apt-get install cuda`
	5. `shutdown -r now` 
	6. __非常重要:__ 在UEFI界面，记住用非安全模式启动，否则会无法加载nvidia显卡，抛错误:`insecure mode boot`
	7. cuda_home变量设置: 
	
	   ~~~
	   echo 'export CUDA_HOME=/usr/local/cuda' >> ~/.bashrc
	   echo 'export LD_LIBRARY_PATH=”$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64"' >> ~/.bashrc
	    ~~~
	
	1. CUDA安装完毕

1. sample 安装
	1. 	用CUDA自带的脚本就可以安装sample了,前面的步骤跑完以后可以直接敲命令`cuda-install-samples-8.0.sh <dir>`, 这是cuda自带的脚本，会把样例代码拷贝到你指定的目录下去，然后你就可以在该目录make编译所有的samples了，直接敲击命令`make`进行编译.

	
### 安装 cuDNN
注意，cuDNN需要注册NVIDIA的会员(免费)才能下载，无法在远程机器上用`curl`或者`wget`下载. 如果真要在远程机器上下载，可以尝试用`ssh -XC user@remotehost`, 把X11 forward到本地，然后开启firefox下载。X11 forward是不需要desktop支持的，相当方便。

1. 下载cuDNN 5.1, 不要下载6.0, 我用6.0遇到过问题,cuda和cudnn版本不兼容。

2. 安装cuDNN 

	~~~
		tar -zxvf cudnn-8.0-linux-x64-v5.1.tgz
		cd cuda
		sudo cp lib64/* /usr/local/cuda/lib64/
		sudo cp include/* /usr/local/cuda/include/
	~~~
		
1. cuDNN完成


### Tensorflow 安装 native pip
1. 安装: pip install tensorflow-gpu
2. 检测环境是否安装成功：

	~~~
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
>>> print(sess.run(hello))
~~~

# 辅助脚本
1. `dpkg -l | grep nvidia    # 查看装了哪些包``
2. `lspci | grep -i nvidia   # 查看N卡驱动是否加载了`
3. `nvidia-smi # 查看nvidi gpu 负载信息`
4. `lsmod | grep nouveau # 检测nouveau 显示驱动是否有加载``
5. `cat /proc/driver/nvidia/version # 检测nvidia驱动是否正常加载`
6. `dmesg | grep -i nvidia # 开机信息`
7. `hostname #查看机器host name`
8. `ssh-copy-id user@hostname.local #安装ssh key到远程服务器`
9. `cuda-install-samples-8.0.sh .  # 安装cuda samples, 这个脚本是cuda toolkit自带的`
10. `Ctrl + Alt + F1  # 机器启动以后进入tty界面`

# 跑分数据
 
## [neural-style](https://github.com/anishathalye/neural-style) 跑分
 
 和amazon g2 基础套餐相比，gtx 1080Ti速度大概是它的十倍，跑neural style速度
 1. macbook pro 2015 mid, i7 2.5 GHz, 大概用了200分钟
 2. amazon g2 $0.7/hour 套餐，大概用了15分钟
 3. 1080Ti, 接近一分钟.
 
 
 
## nbody 跑分

nbody 是nvidia samples 里面自带的一个程序，编译sample code就可以在bin目录下找到该程序，可以做非常简单的性能测试.

~~~
~/NVIDIA_CUDA-8.0_Samples/5_Simulations/nbody$ make
~/NVIDIA_CUDA-8.0_Samples/5_Simulations/nbody$ ../../bin/x86_64/linux/release/nbody -benchmark -numbodies=256000 -device=0
Run "nbody -benchmark [-numbodies=<numBodies>]" to measure performance.
	-fullscreen       (run n-body simulation in fullscreen mode)
	-fp64             (use double precision floating point values for simulation)
	-hostmem          (stores simulation data in host memory)
	-benchmark        (run benchmark to measure performance)
	-numbodies=<N>    (number of bodies (>= 1) to run in simulation)
	-device=<d>       (where d=0,1,2.... for the CUDA device to use)
	-numdevices=<i>   (where i=(number of CUDA devices > 0) to use for simulation)
	-compare          (compares simulation results running once on the default GPU and once on the CPU)
	-cpu              (run n-body simulation on the CPU)
	-tipsy=<file.bin> (load a tipsy model file for simulation)

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.

> Windowed mode
> Simulation data stored in video memory
> Single precision floating point simulation
> 1 Devices used for simulation
gpuDeviceInit() CUDA Device [0]: "GeForce GTX 1080 Ti
> Compute 6.1 CUDA device: [GeForce GTX 1080 Ti]
number of bodies = 256000
256000 bodies, total time for 10 iterations: 1743.828 ms
= 375.817 billion interactions per second
= 7516.338 single-precision GFLOP/s at 20 flops per interaction
~~~

# 错误解决
1. 运行tensorflow脚本时抛错误: `ImportError: libcudnn.so.5: cannot open shared object file: No such file or directory`
   1. 保证安装了cuDNN 5.1， 如果你装的是cuDNN 6.0, 请重装cuDNN 5.1
   2. 把cuda_home变量设置正确,参考3.7
 
1. 系统启动以后屏幕黑屏，不进入登入界面。具体原因未知, 可能是因为未装desktop。解决办法就是Ctrl + Alt + F1, 进入命令行tty登录界面。 



# 参考
1. [Installing Nvidia, Cuda, CuDNN, TensorFlow and Keras](https://medium.com/@acrosson/installing-nvidia-cuda-cudnn-tensorflow-and-keras-69bbf33dce8a)
2. [install tensorflow with GPU](https://www.tensorflow.org/install/install_linux)
3. [NVIDIA Cuda installation guide for linux](http://docs.nvidia.com/cuda/cuda-installation-guide-linux/#axzz4jKGMjRru)
4. [cuDNN download](https://developer.nvidia.com/cudnn)
5. [Tensorflow docker GPU安装运行](https://www.tensorflow.org/install/docker#examples_using_gpu-enabled_images)
6. [nvidia-docker安装运行](https://github.com/NVIDIA/nvidia-docker)
